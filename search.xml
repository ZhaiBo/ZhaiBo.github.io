<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tomcat自动部署war包到ROOT目录]]></title>
    <url>%2F2019%2F09%2F19%2Ftomcat%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2war%E5%8C%85%E5%88%B0ROOT%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;本篇文章说明了tomcat自动部署war包到ROOT目录。 需求部署war包到tomcat，访问路径为localhost:8080，不带项目名称。直接放到webapps下，自动解压后，访问路径需要带项目名称。 部署步骤 解压tomcat包。 在根目录下创建一个新的文件夹wars，并将要部署的war包放进去。 删除原本webapps下的所有文件。 修改conf目录下server.xml，在文件末尾Host标签中加上如下配置: 1&lt;Context path=&quot;/&quot; docBase=&quot;../wars/project.war&quot; reloadable=&quot;true&quot; crossContext=&quot;true&quot; /&gt; 启动tomcat，会将war自动解压到webapps下的ROOT目录，这样就可以直接通过localhost:8080访问项目了。 注意事项 一定要删除webapps下的所有文件。 创建新的目录存放要部署的war包，放到webapps下会自动解压，这样ROOT和webapps下都会有解压开的项目。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[堆内存空间和内存分配策略]]></title>
    <url>%2F2019%2F09%2F03%2F%E5%A0%86%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;本编文章总结了堆内存空间结构和内存分配策略。 堆内存空间结构Java 堆主要分为2个区域-年轻代与老年代，年轻代包括Eden 区和 Survivor 区，Survivor 区又分From区和 To区。如下图： Eden区对象会优先在新生代 Eden 区中进行分配，当 Eden 区空间不足时，虚拟机会使用复制算法发起一次 Minor GC（Young GC），清除掉垃圾对象。之后，Eden 区中绝大部分对象会被回收，而那些无需回收的存活对象，将会进到 Survivor 的 From 区（From 区内存不足时，直接进入 Old 区）。 Survivor区Survivor 区相当于是 Eden 区和 Old 区的一个缓冲区。如果没有Survivor 区域，Old区将很快被填满，就会触发Major GC（因为Major GC一般伴随着Minor GC，也可以看做触发了Full GC）。Survivor 的存在意义就是减少被送到老年代的对象，进而减少 Major GC 的发生。Survivor 又分为2个区，一个是 From 区，一个是 To 区。每次执行 Minor GC，会将 Eden 区和 From 存活的对象放到 Survivor 的 To 区（To 区内存不足时，直接进入 Old 区）。 为什么要将Survivor区分成From和To两个区？为了解决内存碎片化的问题。Minor GC 执行后，Eden 区会清空，存活的对象放到了 Survivor 区，而之前 Survivor 区中的对象，可能也有一些是需要被清除的。这时候JVM要使用标记清除算法去清除垃圾对象，而标记清除算法最大的问题就是内存碎片，由于在Eden区中有很多对象是“朝生夕死”的，所以必然会让内存产生严重的碎片化。Survivor 有2个区域，每次 Minor GC时，会将之前 Eden 区和 From 区中的存活对象复制到 To 区域。第二次 Minor GC 时，再将 Eden 区和 To 区中的存活对象再复制到 From 区域，以此反复。这样一来，总有一个Survivor区域是空闲的。这样就解决了内存碎片的问题。 Old区Old区据着2/3的堆内存空间，当对象从新生代中存活下来，就会被拷贝到这里。Major GC 会清理Old区中的对象，每次Major GC 都会触发“Stop-The-World”。内存越大，执行的时间也就越长。由于老年代中对象存活率很高，采用复制算法效率很低，所以老年代垃圾收集采用的是标记整理算法。 内存分配策略内存分配策略主要有以下几点： 对象优先分配在Eden区，如果Eden区没有足够的空间进行分配时，虚拟机执行一次MinorGC。 大对象直接进入老年代（需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄（Age Count）计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，直到达到阀值（默认15次），对象进入老年区。 动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。 空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾收集]]></title>
    <url>%2F2019%2F09%2F01%2FJVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;在日常开发中，我们并不需要去关注垃圾回收，因为JVM动态内存分配和内存回收已经非常成熟了。但为了排查解决线上环境出现的内存泄漏和内存溢出问题，我们还是需要对JVM有一些深入的了解。 哪些内存需要回收？在垃圾回收之前，我们需要先知道哪些垃圾需要被回收，在JVM中有两种判断“对象已死”的方法。 引用计数法简单的描述就是：引用计数法（Reference Counting）给一个对象添加一个引用计数器，每当有一个地方引用这个对象时，就给这个计数器加1；当删除对该对象的引用时，就将这个计数器减1。当计数器为0时，这个对象就被判定成为垃圾。但在对象循环引用时却不会被回收，如下代码： 12345678910111213public static class ReferenceCount &#123; public Object instance;&#125;public static void main(String[] args) &#123; ReferenceCount a = new ReferenceCount(); ReferenceCount b = new ReferenceCount(); a.instance = b; b.instance = a; a = null; b = null; System.gc();&#125; 运行时添加-XX:+PrintGCDetails参数，从打印的GC信息可以看出，两个对象如果互相引用就不会被回收，控制台打印结果如下： 可达性分析法可达性分析法（Reference Counting）的基本思路就是通过一些被称为GC Roots的对象作为起点，从这些节点开始向下搜索，搜索走过的路径被称为引用链（Reference Chain)，当一个对象到GC Roots没有任何引用链相连时（即从GC Roots节点到该节点不可达），则证明该对象没有被引用。如图：可作为GC Roots的对象主要包括： 虚拟机栈（栈帧中的本地变量表）引用的对象。此时obj为GC Root,当obj为null时,GC Root和obj的引用链断掉,obj将被回收。 123456public class Variable &#123;&#125;public void testGC() &#123; Variable obj = new Variable(); obj = null;&#125; 方法区中类静态属性引用的对象。obj为 GC Root，当obj 为 null时，会触发GC，GC Root 无法和obj所指向的 Variable对象 建立关系，会被回收。而 p 作为类的静态属性，也属于 GC Root，Prop对象依然与 GC root 建立着连接，所以此时 Prop对象并不会被回收。 12345678910public class Prop &#123;&#125;public static class Variable &#123; public static Prop p;&#125;public void testGC() &#123; Variable obj = new Variable(); obj.p = new Prop(); obj = null;&#125; 方法区中常量引用的对象。p为常量，作为GC Root，即使obj置null，p仍然能和Prop建立联系，所以不会被回收。 123456789public static class Prop &#123;&#125; public static class Variable &#123; public static final Prop p = new Prop(); &#125; public void testGC() &#123; Variable obj = new Variable(); obj = null; &#125; 本地方法栈（Native Method）引用的对象。 需要注意的是：即使一个对象未被引用，也并不一定会被回收。如果一个对象执行了finalize()方法，它仍然可以存活，而且finalize()只会执行一次。 垃圾收集算法主要包括标记-清除算法（Mark-Sweep）、复制算法（Copying）、标记整理算法（Mark-Compact）、分代收集算法（Generational Collection）。 标记清除算法分为标记和清除两个阶段，首先标记出所有需要回收的对象，标记完成之后统一对标记的对象进行回收。主要的缺点是：1、效率问题，标记和清除两个过程的效率都不高。2、空间问题，标记清除之后会产生大量的不连续的内存碎片，如果需要分配空间给大对象，就得提前触发另一次垃圾收集，腾出连续的内存空间。 复制算法复制算法是为了解决效率问题而出现的，将可用内存分成大小相等的两块，每次只使用其中的一块，当这一块用完了，就将存活的对象复制到另一块上，再将使用过的内存空间一次清理。这样做的优点是不用考虑内存碎片的问题、实现简单、运行高效。但是每次只能使用原来内存的一半。执行的示意图如下： 标记-整理算法标记整理算法的标记过程和标记清除一致，但后续步骤不是直接清除可回收对象，而是让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存，如下图： 分代收集算法这种算法没有提出新的思想，只是根据对象的存活周期的不同将内存划分为几块。一般把java堆内存分为新生代和老年代，根据各个年代去选择合适的收集算法。比如：新生代垃圾收集的时候总是有大批对象被收集，只有少量对象存活，那就使用复制算法，只需要复制少量对象就可以完成垃圾收集。老年代对象存活率高就使用标记-清除或标记整理。 本文部分内容来自: &gt; 《深入理解Java虚拟机 JVM高级特性与最佳实践》 周志明 著]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM运行时数据区]]></title>
    <url>%2F2019%2F08%2F27%2FJVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;本篇文章总结了JVM运行时数据区。 简介JVM在执行java程序的过程中会把它管理的内存划分为若干个不同的数据区域。主要分为五个区域：堆(Heap)、栈(Stack)、本地方法栈(Native Stack)、方法区(Method Area)、程序计数器(Program Count Register)。如图: 程序计数器（Program Counter Register） 处于线程独占区。 较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。 如果线程执行的是Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的是native方法，这个计数器的值为undefined。 此区域是唯一一个在Java虚拟机规范中没有规定任何OOM情况的区域。 虚拟机栈（Java Virtual Machine Stacks）虚拟机栈描述的是Java方法执行的动态内存模型，处于线程独占区。 栈帧栈帧是方法运行时的基本数据结构。每个方法执行，都会创建一个栈帧，伴随着方法从创建到执行完成。用来存储局部变量表、操作数栈、动态链接、方法出口等。 局部变量表存放编译期可知的各种基本数据类型,对象引用和returnAddress类型。如果线程请求的栈深度大于虚拟机允许的深度，抛出StackOverFlowError，如果虚拟机可动态扩展，但无法申请到足够的内存，会抛出OutOfMemoryError。 本地方法栈（Native Method Stack）与虚拟机栈类似，区别为虚拟机栈执行Java方法，本地方法栈执行Native方法。 Java堆（Java Heap） 处于线程共享区。 所有线程共享的一块内存区域，虚拟机启动时创建。 存放对象实例，几乎所有对象实例都在这里分配内存。 垃圾收集的主要区域。 可细分为：新生代和老年代。 方法区（Method Area） 处于线程共享区。 存储已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 无法满足内存分配需求时，抛出OutOfMemoryError。 运行时常量池（Runtime Constant Pool） 运行时常量池是方法区的一部分。 存放编译期生成的各种字面量和符号引用。 直接内存（Direct Memory） 不是虚拟机运行时数据区的一部分，也不是JVM规范中定义的内存区域。 （New Input/Output）可使用Native函数库直接分配堆外内存，通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用来操作这块内存。 动态扩展时可能会抛出OutOfMemoryError。 参考： 《深入理解Java虚拟机 JVM高级特性与最佳实践》 周志明 著]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Executor线程池框架]]></title>
    <url>%2F2019%2F08%2F09%2FExecutor%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Executor简介Executor是JDK1.5之后引入的，其内部使用了线程池机制，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。如下为Executor相关类图: Executor使用Java提供了Executors工具类，实际使用中我们可以根据需要选择合适的方法去创建和使用线程池。以下为四种主要的方法: newFixedThreadPool(nThreads)，创建一个固定大小的线程池，可控制线程最大并发数，当无可用线程时，任务会在队列中等待。示例代码: 1234567ExecutorService executorService = Executors.newFixedThreadPool(3);for (int i = 0; i &lt; 10; i++) &#123; executorService.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; -- executed&quot;); &#125;);&#125;executorService.shutdown(); newCachedThreadPool，创建一个可缓存线程池，如果线程池长度超过处理需要，可回收空闲线程，若无可回收线程，则新建。示例代码: 1234567ExecutorService executorService1 = Executors.newCachedThreadPool();for (int i = 0; i &lt; 10; i++) &#123; executorService.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; -- executed&quot;); &#125;);&#125;executorService.shutdown(); newScheduledThreadPool，创建一个固定长度的线程池，支持定时及周期性任务执行。示例代码: 12345678// 延迟0秒int initialDelay = 0;// 每隔三秒执行int period = 3;ScheduledExecutorService executor = Executors.newScheduledThreadPool(3);executor.scheduleAtFixedRate(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; -- executed&quot;);&#125;, initialDelay, period, TimeUnit.SECONDS); newSingleThreadExecutor，创建一个单线程的线程池，它可以保证所有任务顺序执行。示例代码:12345678ExecutorService executorService = Executors.newSingleThreadExecutor();for (int i = 0; i &lt; 5; i++) &#123; final int index = i; executorService.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; -- &quot; + &quot;i=&quot; + index); &#125;); &#125; executorService.shutdown(); 执行结果如下: 在阿里的Java开发者手册中，是强制不允许使用Executors去创建线程池，如下图实际使用时，可以参考。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池-ThreadPoolExecutor]]></title>
    <url>%2F2019%2F08%2F08%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0-ThreadPoolExecutor%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;多线程虽然能够最大限度发挥多核计算机的计算能力，但是如果使用不当，反而会对系统造成负担。线程本身也要占用内存空间，大量的线程会占用大量内存资源，为了避免重复的创建线程，就需要一个线程管理者来创建和销毁线程。 什么是线程池?WIKI: 线程池（ThreadPool）是一种线程使用模式。线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代价。线程池不仅能够保证内核的充分利用，还能防止过分调度。可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络sockets等的数量。 为什么要使用线程池?在Java中，要启动一个线程，通常有三种方式: 继承Thread类。 实现Runnable接口。 直接使用Thread类构造函数(new Thread)。 这么做会有以下缺点: 每次new Thread新建对象性能差。 线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。 缺乏更多功能，如定时执行、定期执行、线程中断。 线程池的优点： 重用存在的线程，减少对象创建、消亡的开销，性能佳。 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。 提供定时执行、定期执行、单线程、并发数控制等功能。 如何使用线程池？Java中提供了ThreadPoolExecutor类，此类提供了许多构造函数，可通过如下方式创建使用线程池。12345678910111213141516171819202122232425262728293031323334353637public class ThreadPoolDemo &#123; static AtomicInteger threadNumber = new AtomicInteger(1); public static void main(String[] args) &#123; int corePoolSize = 2; int maximumPoolSize = 5; long keepAliveTime = 60; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; // 自己制定规则 return new Thread(Thread.currentThread().getThreadGroup(), r, &quot;线程&quot; + threadNumber.getAndIncrement(), 0); &#125; &#125;, new RejectedExecutionHandler() &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; throw new RuntimeException(); &#125; &#125; ); for (int i = 0; i &lt; 10; i++) &#123; threadPoolExecutor.execute(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; -- executed&quot;); &#125;); &#125; threadPoolExecutor.shutdown(); &#125;&#125; ThreadPoolExecutor构造函数参数说明,实际使用时选择合适的构造函数即可: corePoolSize，核心线程数量，线程池的基本大小，即在没有任务需要执行的时候线程池的大小。 maximumPoolSize，线程池中允许的最大线程数，线程池中的当前线程数目不会超过该值。如果队列中任务已满，并且当前线程个数小于maximumPoolSize，那么会创建新的线程来执行任务。 keepAliveTime，无任务执行时，最多保持多久时间终止。 unit,keepAliveTime的时间单位。 workQueue,阻塞队列,根据业务场景选择合适的阻塞队列。 threadFactory，线程工厂。 rejectHandler，拒绝任务时的策略。 ThreadPoolExecutor类常用方法 execute，提交任务给线程池执行。 submit，提交任务，能够返回执行结果 shutdown，等待任务执行完后，关闭线程池。 shutdownNow，关闭线程池，不等待任务执行完。 getTaskCount，已执行和未执行的任务总数。 getActiveCount，正在执行的任务总数。 getPoolSize，线程池当前的线程数量。 getCompletedTaskCount，已完成的任务数量。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS下Docker搭建ES、Kibana、Cerebro]]></title>
    <url>%2F2019%2F07%2F19%2FCentOS%E4%B8%8BDocker%E6%90%AD%E5%BB%BAES%E3%80%81Kibana%E3%80%81Cerebro%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;在Docker容器中运行Elasticsearch, Kibana和Cerebro,快速体验ES生态。 安装Docker CE卸载旧版本docker12345678yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-engine 安装依赖包123yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 设置仓库123yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 可选项1yum-config-manager --enable docker-ce-nightly 1yum-config-manager --enable docker-ce-test 1yum-config-manager --disable docker-ce-nightly 安装Docker CE1yum install docker-ce docker-ce-cli containerd.io 启动1systemctl start docker 1docker run hello-world 运行ES、Kibana、Cerebro配置创建docker-compose.yaml，内容为123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172version: &apos;2.2&apos;services: cerebro: image: lmenezes/cerebro:0.8.3 container_name: cerebro ports: - &quot;9000:9000&quot; command: - -Dhosts.0.host=http://elasticsearch:9200 networks: - es7net kibana: image: docker.elastic.co/kibana/kibana:7.1.0 container_name: kibana7 environment: - I18N_LOCALE=zh-CN - XPACK_GRAPH_ENABLED=true - TIMELION_ENABLED=true - XPACK_MONITORING_COLLECTION_ENABLED=&quot;true&quot; ports: - &quot;5601:5601&quot; networks: - es7net elasticsearch: image: docker.elastic.co/elasticsearch/elasticsearch:7.1.0 container_name: es7_01 environment: - cluster.name=geektime - node.name=es7_01 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - discovery.seed_hosts=es7_01 - cluster.initial_master_nodes=es7_01,es7_02 ulimits: memlock: soft: -1 hard: -1 volumes: - es7data1:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - es7net elasticsearch2: image: docker.elastic.co/elasticsearch/elasticsearch:7.1.0 container_name: es7_02 environment: - cluster.name=geektime - node.name=es7_02 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - discovery.seed_hosts=es7_01 - cluster.initial_master_nodes=es7_01,es7_02 ulimits: memlock: soft: -1 hard: -1 volumes: - es7data2:/usr/share/elasticsearch/data networks: - es7netvolumes: es7data1: driver: local es7data2: driver: localnetworks: es7net: driver: bridge 启动1docker-compose up 浏览器访问用户名/密码:admin/12345612http://ip:5601http://ip:9200]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库设计规范-MySQL5.7]]></title>
    <url>%2F2019%2F07%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83-MySQL5-7%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;数据库设计规范-MySQL5.7,参考。 整理自慕课网《高性能可扩展MySQL数据库设计及架构优化 电商项目》 总览 数据库命名规范 数据库基本设计规范 数据库索引设计规范 数据库字段设计规范 SQL开发规范 数据库操作规范 数据库命名规范 所有数据库对象名称必须使用小写字母并用下划线分割 所有数据库对象名称禁止使用mysql保留关键字 数据库对象的命名要能做到见名知义，并且最好不要超过32个字符 所有的临时表必须以 tmp 为前缀并以日期为后缀 | 备份库必须以bak为前缀并以日期为后缀 所有存储相同数据的列名和列类型必须一致 数据库基本设计规范 所有表必须使用Innodb存储引擎。5.6 以后的默认引擎支持事务，行级锁，更好的恢复性，高并发下性能最好 数据库和表字符集统一使用UTF8,一个汉字占用3个字节（ UTF-8 ） 所有的表个字段都需要添加注释 尽量控制单表数据量的大小，建议控制在500万以内 谨慎使用MySQL分区表 分区表在物理上表现为多个文件，在逻辑上表现为一个表 谨慎选择分区表，跨分区查询效率可能更低,建议采用物理分表的方式管理大数据。 尽量做到冷热数据分离，减小表的宽度 减少磁盘IO，保证热数据的内存缓存命中 利用更有效的缓存，避免读入无用的冷数据 经常使用的列放在一个表。 禁止在表中建立预留字段 禁止字数据库中存储图片，文件等二进制数据（要存的话使用BLOB类型） 禁止在线上做数据库压力测试 禁止从开发环境，测试环境直接连生产数据库环境（环境隔离） 数据库索引设计规范 限制每张表的索引数量，建议单张表索引不超过5个 索引不是越多越好，索引可以提高效率同时也可以降低效率 索引可以增加查询效率，但同样也会降低插入和更新效率 禁止给表中的每一列都建立单独的索引 每个Innodb表必须有一个主键 不使用更新频繁的列作为主键，不使用多列主键 不使用UUID，MD5，HASH，字符串作为主键 主键建议使用自增ID 常见索引列建议 select，update，delete从句的where从句中的列 包含order by，group by， distinct中的字段 多表 join 的关联列 如何选择索引列的顺序 区分度最高的列放在联合索引的最左侧 尽量把字段长度最小的列放在联合索引的最左侧 使用最频繁的列放在联合索引的左侧 避免建立冗余索引和重复索引 对应频繁的查询优先考虑使用覆盖索引 尽量避免使用外键约束 不建议使用外键约束，但一定在表与表之间的关联键上建立索引 外键建议在业务端实现 外键会影响父表和子表的写操作从而降低性能 数据库字段设计规范 优先选择符合存储需要的最小的数据类型 将字符串转换为数字类型存储 123-- ip 使用数字存储INET_ATON(&apos;255.255.255.255&apos;) = 4294967295 -- 将ip字符串转为数字INET_NTOA(4294967295) = &apos;255.255.255.255&apos; -- 将数字转为ip字符串 对于非负型的数据来说，要优先使用无符号整形来存储 避免使用TEXT、BLOB数据类型 建议把BLOB，TEXT列分离到单独的扩展表中 TEXT，BLOB类型只能使用前缀索引 避免使用ENUM类型 内部使用整数存储 修改ENUM值需要使用ALTER语句,修改元数据会有元数据锁 ENUM类型的ORDER BY操作效率低，需要额外的操作 禁止使用数值作为枚举值 尽可能把所有列定义为NOT NULL 索引NULL列需要额外的空间来保存，所以会占用更多空间 进行比较和计算时会对NULL值做特别的处理 使用TIMESTAMP或DATETIME类型存储时间 同财务相关的金额类数据，必须使用decimal类型 decimal占用的空间由定义的宽度决定 可用于存储比bigint更大的整数数据 SQL开发规范 建议使用预编译语句进行数据库操作 避免数据类型的隐式转换（索引会失效） 充分利用表上已经存在的索引 避免使用双%的查询条件 a like ‘%123%’ 一个SQL只能利用到复合索引中的一列进行范围查询 使用left join或 not exists 来优化 not in 操作 程序连接不同的数据库使用不同的账号，禁止跨库查询 禁止使用 SELECT * 查询 消耗更多的CPU和IO以及网络带宽资源 无法覆盖到索引 禁止使用不含字段列表的INSERT语句 避免使用子查询，可以把子查询优化为join操作 子查询结果集无法使用索引 子查询会产生临时表，如果子查询数据量大则严重影响效率 消耗过多的CPU和IO资源 避免使用join关联太多的表 每join一个表会多占一部分内存（join_buffer_size） 会产生临时表操作，影响查询效率 MYSQL最多允许关联61个表，建议不超过5个 减少同数据库的交互次数 数据库更适合处理批量操作 合并多个相同操作的操作到一起，可以提高处理效率 禁止使用order by rand() 进行随机排序 会把表中所有符合条件呢的数据装入内存中进行排序 会消耗大量的CPU以及IO资源 禁止在where从句中对列进行函数转换和计算 在明显不会有重复值时使用UNION ALL 而不是 UNION UNION会把所有数据放到临时表中后再进行去重操作 UNION ALL不会再对结果集进行去重操作 拆分复杂的大SQL为多个小SQL MYSQL一个SQL只能使用一个CPU进行计算 SQL拆分后可以通过并行执行来提高处理效率 数据库操作规范 超过100万行的批量操作，要分批多次进行操作 对于大表使用pt-online-schema-change工具修改表结构 禁止为程序使用的账号赋予super权限 对于程序连接数据库的账号，遵循权限最小原则，例如:应用程序使用的帐号不应该具有drop权限]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos下redis的安装及配置]]></title>
    <url>%2F2018%2F06%2F11%2Fcentos%E4%B8%8Bredis%E7%9A%84%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装redis依赖12yum install -y gcc-c++yum install -y tcl 下载redis并安装12345cd /usr/local/wget http://download.redis.io/releases/redis-3.2.9.tar.gztar -zxvf redis-3.2.9.tar.gzcd redis-3.2.9 make &amp;&amp; make test &amp;&amp; make install redis的生产环境启动方案第一步:&emsp;将redis utils目录下redis_init_script脚本,copy到/etc/init.d目录中,将redis_init_script重命名为redis_7000,7000是这个redis实例监听的端口号.给脚本读写执行的权限. 1234cp ./utils/redis_init_script /etc/init.d/cd /etc/init.dmv redis_init_script redis_7000chmod 777 redis_7000 第二步:&emsp;修改redis_7000脚本的第6行的REDISPORT，设置为相同的端口号(7000),并在顶部加上以下内容.让脚本开机执行. 12# chkconfig: 2345 90 10# description: Redis is a persistent key-value database 1chkconfig redis_7000 on 第三步:&emsp;创建两个目录：/etc/redis（存放redis的配置文件），/var/redis/7000（存放redis的持久化文件）. 123mkdir /etc/redismkdir /var/redismkdir /var/redis/7000 第四步:&emsp;修改redis配置文件（默认在redis安装目录下，redis.conf），拷贝到/etc/redis目录中，修改名称为7000.conf.要修改的配置为: 1234daemonize yes pidfile /var/run/redis_7000.pid port 7000dir /var/redis/7000 1cd /usr/local/redis-3.2.9 12cp ./redis.conf /etc/redismv redis.conf 7000.conf 第五步:&emsp;启动redis 12./redis_7000 startps -ef | grep redis redis-cli的使用连接本机的端口停止redis进程,ip为本机,端口为6379时可不写 1redis-cli -h 127.0.0.1 -p 7000 SHUTDOWN， ping redis的端口，查看是否正常 1redis-cli -p 7000 PING 进入交互式命令行 1redis-cli -p 7000 接着就可以使用redis存取命令操作redis。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序实现倒计时的效果]]></title>
    <url>%2F2018%2F06%2F07%2F%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%AE%9E%E7%8E%B0%E5%80%92%E8%AE%A1%E6%97%B6%E7%9A%84%E6%95%88%E6%9E%9C%2F</url>
    <content type="text"><![CDATA[实现效果图： 实现思路:&emsp;&emsp;在onload函数里每秒调用一次getOverTime()函数，此函数将毫秒转换成HH:mm:ss的时间格式，最后重新赋值倒计时文本. wxml文件代码:1&lt;view class=&apos;exam-time&apos;&gt;&#123;&#123;overTime&#125;&#125;&lt;/view&gt; js代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 onLoad: function (options) &#123; let that = this; let endTime = &apos;2018-06-07 19:42:23&apos;; //总剩余秒数 let time = (Date.parse(new Date(endDate)) - Date.parse(new Date())) / 1000; console.log(time); if (time &gt; 1) &#123; setInterval(function () &#123; //每秒调用一次,剩余时间减去1秒 time -= 1; that.getOverTime(time); &#125;, 1000) &#125; else &#123; that.setData(&#123; overTime: &apos;时间到&apos; &#125;); &#125; &#125;, /** * 将剩余时间转换成毫秒数，换算成 HH:mm:ss的时间格式 */getOverTime: function (overSecond) &#123; let that = this; var overTime; if (null != overSecond &amp;&amp; &quot;&quot; != overSecond) &#123; if (overSecond &gt; 0 &amp;&amp; overSecond &lt; 60 * 60) &#123; // 一小时内 let minute = Math.floor(overSecond / 60 % 60); if (minute &lt; 10) &#123; minute = &apos;0&apos; + minute; &#125; let second = Math.floor(overSecond % 60); if (second &lt; 10) &#123; second = &apos;0&apos; + second; &#125; overTime = minute + &apos;:&apos; + second; &#125; else if (overSecond &gt;= 60 * 60 &amp;&amp; overSecond &lt; 60 * 60 * 24) &#123; //一天内 var hour = Math.floor(overSecond / 3600 % 24); if (hour &lt; 10) &#123; hour = &apos;0&apos; + hour; &#125; let minute = Math.floor(overSecond / 60 % 60); if (minute &lt; 10) &#123; minute = &apos;0&apos; + minute; &#125; let second = Math.floor(overSecond % 60); if (second &lt; 10) &#123; second = &apos;0&apos; + second; &#125; overTime = hour + &apos;:&apos; + minute + &apos;:&apos; + second; &#125; else &#123; return; &#125; &#125; console.log(overTime); that.setData(&#123; overTime: &apos;倒计时&apos; + overTime &#125; ); &#125;]]></content>
      <categories>
        <category>小程序</category>
      </categories>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[POI转换Excel为List]]></title>
    <url>%2F2018%2F05%2F17%2FPOI%E8%BD%AC%E6%8D%A2Excel%E4%B8%BAList%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;使用POI将Excel文件转换成List,实现批量导入数据的功能. 引入POI所依赖的Jar包12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.10-FINAL&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.10-FINAL&lt;/version&gt;&lt;/dependency&gt; 转换Excel文件为List集合&emsp;&emsp;这里需要先定义实体，字段数量与Excel列数相同。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/** * @param filePath 文件路径 * @param clazz 自定义实体 */ public static &lt;T&gt; List&lt;T&gt; getListFromExcel(String filePath, Class&lt;T&gt; clazz) throws Exception &#123; if (&quot;&quot;.equals(filePath)) &#123; throw new IllegalArgumentException(&quot;Excel读取错误!&quot;); &#125; InputStream is = new FileInputStream(filePath); //读取Excel内容 List&lt;List&lt;String&gt;&gt; list = ExcelUtil.readExcel(is); List&lt;T&gt; listBean = new ArrayList&lt;T&gt;(); //获取传进来的实体所有setter方法 List&lt;Method&gt; setMethods = getSetMethods(clazz); for (int i = 1; i &lt; list.size(); i++) &#123; T ins = clazz.newInstance(); List&lt;String&gt; listStr = list.get(i); for (int j = 0; j &lt; listStr.size(); j++) &#123; //调用Set方法赋值 if (j &lt; setMethods.size()) &#123; setMethods.get(j).invoke(ins, listStr.get(j)); &#125; &#125; listBean.add(ins); &#125; return listBean; &#125; public static List&lt;List&lt;String&gt;&gt; readExcel(InputStream is) &#123; Workbook wb = null; try &#123; wb = WorkbookFactory.create(is); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(&quot;Excel读取错误!&quot;); &#125; /* 得到第一个sheet */ Sheet sheet = wb.getSheetAt(0); /* 得到Excel的行数 */ int totalRows = sheet.getPhysicalNumberOfRows(); /* 得到Excel的列数 */ int totalCells = 0; if (totalRows &gt;= 1 &amp;&amp; sheet.getRow(0) != null) &#123;// 校验行数 totalCells = sheet.getRow(0).getPhysicalNumberOfCells(); &#125; List&lt;List&lt;String&gt;&gt; dataLst = new LinkedList&lt;List&lt;String&gt;&gt;(); /* 循环Excel的行 */ for (int r = 0; r &lt; totalRows; r++) &#123; Row row = sheet.getRow(r); if (row == null) continue;// 本行为空则结束本次循环 List&lt;String&gt; rowLst = new LinkedList&lt;String&gt;(); /* 循环Excel的列 转换单元格值为String*/ for (int c = 0; c &lt; totalCells; c++) &#123; Cell cell = row.getCell(c); String cellValue = &quot;&quot;; if (null != cell) &#123; switch (cell.getCellType()) &#123; case Cell.CELL_TYPE_NUMERIC: // 数字 cellValue = cell.getNumericCellValue() + &quot;&quot;; break; case Cell.CELL_TYPE_STRING: // 字符串 cellValue = cell.getStringCellValue(); break; case Cell.CELL_TYPE_BOOLEAN: // Boolean cellValue = cell.getBooleanCellValue() + &quot;&quot;; break; case Cell.CELL_TYPE_FORMULA: // 公式 cellValue = cell.getCellFormula() + &quot;&quot;; break; case Cell.CELL_TYPE_BLANK: // 空值 cellValue = &quot;&quot;; break; case Cell.CELL_TYPE_ERROR: cellValue = &quot;非法字符&quot;; break; default: cellValue = &quot;未知类型&quot;; break; &#125; &#125; rowLst.add(cellValue); &#125; /* 保存第r行的第c列 */ dataLst.add(rowLst); &#125; return dataLst; &#125; private static List&lt;Method&gt; getSetMethods(Class clazz) &#123; Class[] parameterTypes = new Class[1]; Field[] fields = clazz.getDeclaredFields(); parameterTypes[0] = null; String filedName = &quot;&quot;; Method method = null; StringBuilder setMethodName = new StringBuilder(); List&lt;Method&gt; setMethods = new ArrayList&lt;Method&gt;(); for (int i = 0; i &lt; fields.length; i++) &#123; fields[i].setAccessible(true); filedName = fields[i].getName(); setMethodName.delete(0,setMethodName.length()); setMethodName.append(&quot;set&quot;).append(filedName.substring(0,1).toUpperCase()).append(filedName.substring(1)); parameterTypes[0] = fields[i].getType(); try &#123; method = clazz.getMethod(setMethodName.toString(), parameterTypes); &#125; catch (NoSuchMethodException e) &#123; e.printStackTrace(); &#125; setMethods.add(method); &#125; return setMethods; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
</search>
